(window.webpackJsonp=window.webpackJsonp||[]).push([[64],{381:function(t,n,s){"use strict";s.r(n);var a=s(42),r=Object(a.a)({},(function(){var t=this,n=t.$createElement,s=t._self._c||n;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"importerror-cannot-import-name-deprecated-from-nltk-internals-的可能解决办法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#importerror-cannot-import-name-deprecated-from-nltk-internals-的可能解决办法"}},[t._v("#")]),t._v(" ImportError: cannot import name 'deprecated' from 'nltk.internals'的可能解决办法")]),t._v(" "),s("p",[t._v("看到网上的文章说nltk做分词效果很好，甚至可以完成单词的时态转换，就想着体验一下。安装完了之后，我运行了这段代码：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" nltk"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("wordnet "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" WordNetLemmatizer\n\nwords "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'gave'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'went'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'going'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'dating'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'comes'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" word "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" words"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("WordNetLemmatizer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lemmatize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("word"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'v'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 还原动词")]),t._v("\n")])])]),s("p",[t._v("但是出现了报错："),s("code",[t._v("ImportError: cannot import name 'deprecated' from 'nltk.internals'")]),t._v("。这跟我写的代码好像没有任何关系，让人有点摸不着头脑。")]),t._v(" "),s("p",[t._v("查了一下，看到有人是这么说的：")]),t._v(" "),s("blockquote",[s("p",[t._v("There happen to be another script with the same name Python is looking for. Python got confused about the script from package and your own script because it start searching from the folder where you are.\nSo just change your own script to another name.")])]),t._v(" "),s("p",[t._v("简而言之，就是当前文件的名称和nltk的某些模块名重合了，导致无法识别。我看了一下，我这个文件叫tokenize.py，确实和nltk的一个分词模块名称冲突了。")]),t._v(" "),s("p",[t._v("改一下名字就可以正常运行了。\n"),s("comment")],1)])}),[],!1,null,null,null);n.default=r.exports}}]);